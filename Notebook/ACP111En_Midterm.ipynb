{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Demo-Web crawler"
      ],
      "metadata": {
        "id": "dXABGbMrUoaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BeautifulSoup\n",
        "\n",
        "__Target__\n",
        "\n",
        "Crawle professors' disciplines from\n",
        "https://csie.asia.edu.tw/en/associate_professors_2"
      ],
      "metadata": {
        "id": "bTpgr9Gyyugi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1"
      ],
      "metadata": {
        "id": "8sp9QgIWB39i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEgPPZVemctO"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup \n",
        "import re\n",
        "pages = set()\n",
        "html = urlopen('https://csie.asia.edu.tw/en/associate_professors_2')\n",
        "bs = BeautifulSoup(html, 'html.parser')\n",
        "for link in bs.find_all('a', href=re.compile('^(http://research.asia.edu.tw/TchEportfolio/)')):\n",
        "  if link.attrs['href'] not in pages:\n",
        "    #We have encountered a new page\n",
        "    newPage = link.attrs['href']\n",
        "    pages.add(newPage)\n",
        "    print(newPage)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2\n",
        "\n",
        "http://research.asia.edu.tw/TchEportfolio/index_1/wenhsu\n",
        "```\n",
        "    ul_items=discipline.find_parent().find_next_siblings('ul')\n",
        "    print(ul_items)\n",
        "    break\n",
        "```"
      ],
      "metadata": {
        "id": "u378Vd2GyrN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_word = 'Discipline expertise'\n",
        "for page in pages:\n",
        "  html2 = urlopen(page)\n",
        "  bs2 = BeautifulSoup(html2, 'html.parser')\n",
        "  professor_name = bs2.find(\"h1\", {\"id\": \"colorlib-logo\"})\n",
        "  professor_discipline = bs2.find(string=re.compile(the_word))\n",
        "  if professor_name:\n",
        "    print(professor_name.text.strip())\n",
        "  if professor_discipline:\n",
        "    print(professor_discipline.parent.find_next_sibling(\"ul\").text)\n"
      ],
      "metadata": {
        "id": "wu6e9CD4yrmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrapy-Ver.1\n",
        "\n",
        "```\n",
        "scrapy startproject csie\n",
        "cd csie/csie/spiders\n",
        "code professor_spider.py\n",
        "scrapy crawl professor\n",
        "scrapy crawl professor -o professors.jl\n",
        "scrapy crawl professor -o professors.json\n",
        "scrapy crawl professor -o professors.csv\n",
        "```"
      ],
      "metadata": {
        "id": "sRHmxijFGcZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#professor_spider.py\n",
        "import scrapy\n",
        "class ProfessorSpider(scrapy.Spider):\n",
        "    name = \"professor\"\n",
        "    start_urls = [\n",
        "        \"https://csie.asia.edu.tw/zh_tw/associate_professors_2\",\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "      #for professor in response.css('//span[@class=\"i-member-value member-data-value-name\"]/text()'):\n",
        "      #for professor in response.xpath('//span[@class=\"i-member-value member-data-value-name\"]/text()'):\n",
        "          yield {\n",
        "              'name': professor.get(),\n",
        "          }"
      ],
      "metadata": {
        "id": "9-eKcK9z9ufY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### settings.py\n",
        "```\n",
        "FEED_EXPORT_ENCODING = 'utf-8'\n",
        "```"
      ],
      "metadata": {
        "id": "ldn3fLJ4hiUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrapy-Ver.2:BeautifulSoup\n",
        "\n",
        "```\n",
        "scrapy crawl discipline -o discipline.jl\n",
        "```"
      ],
      "metadata": {
        "id": "QenOsNtzGFpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#discipline_spider.py\n",
        "import scrapy\n",
        "from bs4 import BeautifulSoup \n",
        "import re\n",
        "class DisciplineSpider(scrapy.Spider):\n",
        "    name = \"discipline\"\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://csie.asia.edu.tw/zh_tw/associate_professors_2',\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "            self.log(f'resuest url {url}')\n",
        "\n",
        "    def parse(self, response):\n",
        "        bs = BeautifulSoup(response.text, 'lxml')\n",
        "        for link in bs.find_all('a', href=re.compile('^(http://research.asia.edu.tw/TchEportfolio/)')):\n",
        "            sub_url = link.attrs['href']\n",
        "            yield scrapy.Request(url=sub_url, callback=self.parse_discipline)\n",
        "\n",
        "    def parse_discipline(self, response):\n",
        "        bs2 = BeautifulSoup(response.body, 'html.parser')\n",
        "        the_word = 'Discipline expertise'\n",
        "        professor_name = bs2.find(\"h1\", {\"id\": \"colorlib-logo\"})\n",
        "        professor_discipline = bs2.find(string=re.compile(the_word))\n",
        "        yield{\n",
        "            'name': professor_name.text.strip(),\n",
        "            'discipline': professor_discipline.parent.find_next_sibling(\"ul\").text,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "T0t-pr6fGNkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrapy-Ver.3: xpath selector\n",
        "\n",
        "```\n",
        "scrapy crawl discipline2 -o discipline2.csv\n",
        "scrapy crawl discipline2 -o discipline2.json\n",
        "scrapy crawl discipline2 -o discipline2.jl\n",
        "```"
      ],
      "metadata": {
        "id": "ityDmxp-bIO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#discipline2_spider.py\n",
        "import scrapy\n",
        "class Discipline2Spider(scrapy.Spider):\n",
        "    name = \"discipline2\"\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://csie.asia.edu.tw/zh_tw/associate_professors_2',\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        for link in response.xpath('//a[contains(@href, \"research.asia.edu.tw\")]/@href').extract():\n",
        "            yield scrapy.Request(link, callback=self.parse_discipline)\n",
        "\n",
        "    def parse_discipline(self, response):\n",
        "        professor_name = response.xpath('//h1[@id=\"colorlib-logo\"]/a/text()').get()\n",
        "        professor_disciplines = response.xpath('//strong[contains(text(),\"Discipline expertise\")]/following::ul[1]//li/text()').extract()\n",
        "        if professor_name:\n",
        "            yield{\n",
        "                'url':response.request.url,\n",
        "                'name': professor_name.strip(),\n",
        "                'discipline': professor_disciplines,\n",
        "            }"
      ],
      "metadata": {
        "id": "pc4CQxQhhqxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selenium\n",
        "\n",
        "https://colab.research.google.com/github/restrepo/ComputationalMethods/blob/master/tools/selenium.ipynb"
      ],
      "metadata": {
        "id": "rDYcpgoch0Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Info:\n",
        "\n",
        "https://chocolatey.org/install\n",
        "```\n",
        "choco install chromedriver\n",
        "```\n",
        "\n",
        "C:\\ProgramData\\chocolatey\\lib\\chromedriver\\tools\\chromedriver.exe"
      ],
      "metadata": {
        "id": "6fL4SMiqQrEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup \n",
        "import re\n",
        "\n",
        "browser = webdriver.Chrome(executable_path = 'C:\\ProgramData\\chocolatey\\lib\\chromedriver\\tools\\chromedriver.exe')\n",
        "browser.get(\"https://csie.asia.edu.tw/en/associate_professors_2\") \n",
        "bs = BeautifulSoup(browser.page_source, 'html.parser')\n",
        "browser.close() \n",
        "pages = set()\n",
        "\n",
        "for link in bs.find_all('a', href=re.compile('^(http://research.asia.edu.tw/TchEportfolio/)')):\n",
        "  if link.attrs['href'] not in pages:\n",
        "    #We have encountered a new page\n",
        "    newPage = link.attrs['href']\n",
        "    pages.add(newPage)\n",
        "    print(newPage)"
      ],
      "metadata": {
        "id": "xTq7wpX0Scl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}